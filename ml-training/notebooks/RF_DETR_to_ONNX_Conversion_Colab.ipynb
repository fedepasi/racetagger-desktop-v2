{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# RF-DETR to ONNX Conversion - Google Colab\n",
    "\n",
    "Questo notebook ti guida nella conversione di modelli RF-DETR trainati (formato `.pt` o `.pth`) in formato ONNX per inferenza locale o deployment.\n",
    "\n",
    "## üìã Cosa faremo:\n",
    "\n",
    "1. Installare le dipendenze necessarie\n",
    "2. Caricare il tuo modello `.pt` trainato su Roboflow\n",
    "3. Rilevare automaticamente la dimensione del modello\n",
    "4. Convertire in formato ONNX\n",
    "5. Verificare e semplificare il modello\n",
    "6. Scaricare il risultato\n",
    "\n",
    "## ‚ö†Ô∏è Nota Importante: PyTorch 2.9+\n",
    "\n",
    "PyTorch 2.9+ usa `torch.export` per default, che **non √® compatibile** con RF-DETR. Questo notebook usa il legacy exporter (`dynamo=False`) per compatibilit√†.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß Step 1: Setup & Installazione Dipendenze\n",
    "\n",
    "Installiamo tutte le librerie necessarie. Questo potrebbe richiedere 2-3 minuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Installa dipendenze\n",
    "!pip install -q rfdetr==1.3.0 onnx==1.19.0 onnxsim==0.4.36 torch==2.8.0 torchvision\n",
    "\n",
    "print(\"‚úÖ Installazione completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## üì§ Step 2: Upload del Modello .pt\n",
    "\n",
    "Carica il tuo file `.pt` o `.pth` trainato su Roboflow.\n",
    "\n",
    "**Opzione A**: Upload manuale (clicca il pulsante qui sotto)  \n",
    "**Opzione B**: Mount Google Drive (se il file √® nel tuo Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_file"
   },
   "outputs": [],
   "source": [
    "# OPZIONE A: Upload manuale\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üìÅ Carica il tuo file .pt o .pth:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Ottieni il nome del file caricato\n",
    "checkpoint_path = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ File caricato: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# OPZIONE B: Mount Google Drive (esegui solo se usi Drive)\n",
    "# Uncomment le righe sotto per usare Google Drive\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Specifica il percorso del tuo file nel Drive\n",
    "# checkpoint_path = '/content/drive/MyDrive/path/to/your/model.pt'\n",
    "# print(f\"‚úÖ Usando file da Drive: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inspect"
   },
   "source": [
    "## üîç Step 3: Ispezione del Modello\n",
    "\n",
    "Analizziamo il checkpoint per determinare automaticamente:\n",
    "- Risoluzione (resolution)\n",
    "- Hidden dimension\n",
    "- Tipo di modello (Nano/Small/Medium/Base/Large/Seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inspect_checkpoint"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Carica checkpoint per ispezione\n",
    "print(f\"üîç Analizzando checkpoint: {checkpoint_path}...\\n\")\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "args = checkpoint.get('args', None)\n",
    "\n",
    "# Determina tipo di modello\n",
    "model_type = None\n",
    "resolution = None\n",
    "hidden_dim = None\n",
    "\n",
    "if args and hasattr(args, 'resolution'):\n",
    "    resolution = args.resolution\n",
    "    hidden_dim = getattr(args, 'hidden_dim', None)\n",
    "    patch_size = getattr(args, 'patch_size', 'N/A')\n",
    "    \n",
    "    print(f\"üìä Informazioni modello:\")\n",
    "    print(f\"   Resolution: {resolution}\")\n",
    "    print(f\"   Hidden dim: {hidden_dim}\")\n",
    "    print(f\"   Patch size: {patch_size}\\n\")\n",
    "    \n",
    "    # Determina model type\n",
    "    if resolution == 384:\n",
    "        model_type = 'RFDETRNano'\n",
    "    elif resolution == 512:\n",
    "        model_type = 'RFDETRSmall'\n",
    "    elif resolution == 576:\n",
    "        model_type = 'RFDETRMedium'\n",
    "    elif resolution == 560:\n",
    "        if hidden_dim == 256:\n",
    "            model_type = 'RFDETRBase'\n",
    "        elif hidden_dim == 384:\n",
    "            model_type = 'RFDETRLarge'\n",
    "        else:\n",
    "            model_type = 'Unknown'\n",
    "    else:\n",
    "        model_type = 'Unknown'\n",
    "        \n",
    "elif 'model' in checkpoint:\n",
    "    # Instance segmentation model\n",
    "    if len(checkpoint['model']) == 544:\n",
    "        model_type = 'RFDETRSegPreview'\n",
    "        resolution = 560  # Default per Seg\n",
    "    else:\n",
    "        model_type = 'Unknown'\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Impossibile determinare automaticamente il tipo di modello\")\n",
    "    model_type = 'Unknown'\n",
    "\n",
    "print(f\"üéØ Tipo modello rilevato: {model_type}\")\n",
    "print(f\"   Resolution da usare: {resolution}\\n\")\n",
    "\n",
    "if model_type == 'Unknown':\n",
    "    print(\"‚ö†Ô∏è ATTENZIONE: Tipo modello sconosciuto!\")\n",
    "    print(\"   Dovrai specificare manualmente MODEL_CLASS e RESOLUTION nella cella successiva.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "convert"
   },
   "source": [
    "## üîÑ Step 4: Conversione in ONNX\n",
    "\n",
    "Procediamo con la conversione automatica. Se il tipo di modello non √® stato rilevato, modifica manualmente `MODEL_CLASS` e `RESOLUTION`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "convert_onnx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.onnx\n",
    "import onnx\n",
    "from onnxsim import simplify\n",
    "from rfdetr.detr import (\n",
    "    RFDETRSmall, \n",
    "    RFDETRBase, \n",
    "    RFDETRMedium, \n",
    "    RFDETRLarge,\n",
    "    RFDETRNano,\n",
    "    RFDETRSegPreview\n",
    ")\n",
    "import hashlib\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURAZIONE\n",
    "# ============================================\n",
    "\n",
    "# Output path\n",
    "output_path = Path(checkpoint_path).with_suffix('.onnx')\n",
    "\n",
    "# Model class mapping\n",
    "MODEL_CLASSES = {\n",
    "    'RFDETRNano': RFDETRNano,\n",
    "    'RFDETRSmall': RFDETRSmall,\n",
    "    'RFDETRMedium': RFDETRMedium,\n",
    "    'RFDETRBase': RFDETRBase,\n",
    "    'RFDETRLarge': RFDETRLarge,\n",
    "    'RFDETRSegPreview': RFDETRSegPreview\n",
    "}\n",
    "\n",
    "# Se rilevamento automatico fallito, modifica qui:\n",
    "# model_type = 'RFDETRSmall'  # Uncomment e modifica se necessario\n",
    "# resolution = 512             # Uncomment e modifica se necessario\n",
    "\n",
    "if model_type not in MODEL_CLASSES:\n",
    "    raise ValueError(f\"Model type '{model_type}' non riconosciuto. Modifica manualmente nella cella.\")\n",
    "\n",
    "MODEL_CLASS = MODEL_CLASSES[model_type]\n",
    "\n",
    "# ============================================\n",
    "# CONVERSIONE\n",
    "# ============================================\n",
    "\n",
    "print(f\"üöÄ Iniziando conversione...\")\n",
    "print(f\"   Input:  {checkpoint_path}\")\n",
    "print(f\"   Output: {output_path}\")\n",
    "print(f\"   Model:  {model_type}\")\n",
    "print(f\"   Res:    {resolution}\\n\")\n",
    "\n",
    "# Forza CPU e fallback MPS per Mac compatibility\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "# Carica modello\n",
    "print(f\"üì¶ Caricando modello {model_type}...\")\n",
    "model = MODEL_CLASS(pretrain_weights=checkpoint_path)\n",
    "\n",
    "# Prepara il modello per export\n",
    "inner_model = model.model.model\n",
    "inner_model = inner_model.cpu()\n",
    "inner_model.eval()\n",
    "inner_model.export()  # IMPORTANTE: Fixa positional embeddings\n",
    "\n",
    "# Crea dummy input\n",
    "dummy_input = torch.randn(1, 3, resolution, resolution)\n",
    "\n",
    "# Export a ONNX\n",
    "print(f\"\\n‚öôÔ∏è Esportando a ONNX...\")\n",
    "torch.onnx.export(\n",
    "    inner_model,\n",
    "    dummy_input,\n",
    "    str(output_path),\n",
    "    export_params=True,\n",
    "    opset_version=17,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['boxes', 'scores'],\n",
    "    dynamo=False  # CRITICO: Usa legacy exporter (PyTorch 2.9+ compatibility)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Export completato!\")\n",
    "\n",
    "# Verifica ONNX\n",
    "print(f\"\\nüîç Verificando modello ONNX...\")\n",
    "onnx_model = onnx.load(str(output_path))\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(f\"‚úÖ Modello valido!\")\n",
    "\n",
    "# Semplifica\n",
    "print(f\"\\nüîß Semplificando modello...\")\n",
    "model_simplified, check = simplify(onnx_model)\n",
    "if check:\n",
    "    onnx.save(model_simplified, str(output_path))\n",
    "    print(f\"‚úÖ Modello semplificato!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Semplificazione fallita, usando modello non semplificato\")\n",
    "\n",
    "# Calcola checksum\n",
    "print(f\"\\nüîê Calcolando checksum...\")\n",
    "with open(output_path, 'rb') as f:\n",
    "    checksum = hashlib.sha256(f.read()).hexdigest()\n",
    "\n",
    "file_size = os.path.getsize(output_path)\n",
    "\n",
    "# Report finale\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ CONVERSIONE COMPLETATA!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"File:     {output_path}\")\n",
    "print(f\"Size:     {file_size / (1024*1024):.1f} MB\")\n",
    "print(f\"SHA256:   {checksum}\")\n",
    "print(f\"Model:    {model_type}\")\n",
    "print(f\"Res:      {resolution}x{resolution}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "info"
   },
   "source": [
    "## üìä Informazioni sul Modello ONNX\n",
    "\n",
    "### Input/Output Format:\n",
    "\n",
    "**Input**: `[batch, 3, resolution, resolution]`\n",
    "- Immagine RGB normalizzata\n",
    "- Batch size tipicamente = 1\n",
    "- Resolution dipende dal modello (384/512/560/576)\n",
    "\n",
    "**Output boxes**: `[batch, 300, 4]`\n",
    "- Bounding boxes (x1, y1, x2, y2)\n",
    "- Coordinate normalizzate 0-1\n",
    "\n",
    "**Output scores**: `[batch, 300, num_classes]`\n",
    "- Score per ogni classe\n",
    "- Richiede softmax per ottenere probabilit√†\n",
    "\n",
    "### Post-Processing Necessario:\n",
    "\n",
    "1. **Softmax** sugli scores\n",
    "2. **Argmax** per classe predetta\n",
    "3. **Confidence threshold** (es. 0.5)\n",
    "4. **NMS** (Non-Maximum Suppression) per overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## üß™ Step 5: Test del Modello ONNX (Opzionale)\n",
    "\n",
    "Testiamo il modello ONNX convertito con una predizione di prova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_onnx"
   },
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "print(\"üß™ Testing ONNX model...\\n\")\n",
    "\n",
    "# Carica ONNX session\n",
    "session = ort.InferenceSession(str(output_path))\n",
    "\n",
    "# Get input/output info\n",
    "input_name = session.get_inputs()[0].name\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "output_names = [out.name for out in session.get_outputs()]\n",
    "\n",
    "print(f\"üì• Input:\")\n",
    "print(f\"   Name:  {input_name}\")\n",
    "print(f\"   Shape: {input_shape}\\n\")\n",
    "\n",
    "print(f\"üì§ Outputs:\")\n",
    "for i, out in enumerate(session.get_outputs()):\n",
    "    print(f\"   [{i}] {out.name}: {out.shape}\")\n",
    "\n",
    "# Crea dummy input per test\n",
    "dummy_input = np.random.randn(1, 3, resolution, resolution).astype(np.float32)\n",
    "\n",
    "# Run inference\n",
    "print(f\"\\nüîÆ Running test inference...\")\n",
    "outputs = session.run(None, {input_name: dummy_input})\n",
    "\n",
    "print(f\"‚úÖ Inference completata!\\n\")\n",
    "print(f\"   Boxes shape:  {outputs[0].shape}\")\n",
    "print(f\"   Scores shape: {outputs[1].shape}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Modello ONNX funzionante!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## üíæ Step 6: Download del Modello ONNX\n",
    "\n",
    "Scarica il file `.onnx` convertito sul tuo computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_file"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(f\"üì• Downloading {output_path}...\\n\")\n",
    "files.download(str(output_path))\n",
    "print(f\"‚úÖ Download completato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "### Upload su RaceTagger (Supabase)\n",
    "\n",
    "1. Vai al **Management Portal** ‚Üí **Model Manager**\n",
    "2. Seleziona la categoria sport\n",
    "3. Inserisci versione e note\n",
    "4. Upload del file `.onnx`\n",
    "5. Incolla le classi dal training Roboflow\n",
    "6. Il checksum SHA256 viene verificato automaticamente\n",
    "\n",
    "### Esempio Post-Processing Code\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def postprocess(boxes, scores, conf_threshold=0.5, iou_threshold=0.5):\n",
    "    # Softmax\n",
    "    probs = np.exp(scores) / np.exp(scores).sum(axis=-1, keepdims=True)\n",
    "    \n",
    "    # Best class per detection\n",
    "    class_ids = probs.argmax(axis=-1)\n",
    "    confidences = probs.max(axis=-1)\n",
    "    \n",
    "    # Filter by confidence\n",
    "    mask = confidences > conf_threshold\n",
    "    filtered_boxes = boxes[mask]\n",
    "    filtered_scores = confidences[mask]\n",
    "    filtered_classes = class_ids[mask]\n",
    "    \n",
    "    # Apply NMS (use cv2.dnn.NMSBoxes or torchvision.ops.nms)\n",
    "    # ...\n",
    "    \n",
    "    return filtered_boxes, filtered_scores, filtered_classes\n",
    "```\n",
    "\n",
    "### Risorse Utili\n",
    "\n",
    "- **RF-DETR Docs**: https://github.com/roboflow/rf-detr\n",
    "- **ONNX Runtime**: https://onnxruntime.ai/\n",
    "- **Roboflow**: https://roboflow.com/\n",
    "\n",
    "---\n",
    "\n",
    "**Creato per RaceTagger**  \n",
    "*Ultimo aggiornamento: 2026-01-18*  \n",
    "*Testato con: PyTorch 2.8.0, ONNX 1.19.0, rfdetr 1.3.0*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "### Errore: `torch.export` fails\n",
    "\n",
    "**Causa**: PyTorch 2.9+ usa il nuovo dynamo exporter di default.\n",
    "\n",
    "**Soluzione**: Il parametro `dynamo=False` √® gi√† incluso nel codice sopra.\n",
    "\n",
    "### Errore: Position embeddings size mismatch\n",
    "\n",
    "**Causa**: Stai usando il model class sbagliato (risoluzione diversa dal training).\n",
    "\n",
    "**Soluzione**: Verifica la risoluzione nel checkpoint e modifica `MODEL_CLASS` e `RESOLUTION`.\n",
    "\n",
    "### Errore: MPS tensor allocation (Mac M-series)\n",
    "\n",
    "**Causa**: Metal Performance Shaders ha problemi con torch.export.\n",
    "\n",
    "**Soluzione**: Il codice usa gi√† `.cpu()` e `PYTORCH_ENABLE_MPS_FALLBACK=1`.\n",
    "\n",
    "### Errore: `antialias` parameter not supported\n",
    "\n",
    "**Causa**: Vecchie versioni di rfdetr.\n",
    "\n",
    "**Soluzione**: Upgrade a rfdetr 1.3.0 (gi√† fatto nell'installazione).\n",
    "\n",
    "### Modello troppo grande per Colab\n",
    "\n",
    "**Soluzione**: Usa Colab Pro per pi√π RAM/GPU, oppure esegui localmente."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
