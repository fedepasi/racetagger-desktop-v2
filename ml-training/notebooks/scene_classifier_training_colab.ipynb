{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸ RaceTagger Scene Classifier Training - Google Colab\n",
    "\n",
    "Training ottimizzato per scene classification con 3 architetture:\n",
    "- **MobileNetV3-Small** (2.5M params) - Lightweight, target <6MB\n",
    "- **ResNet18** (11.5M params) - Replicare risultati Roboflow (89%)\n",
    "- **EfficientNet-B0** (5.3M params) - Compromesso size/accuracy\n",
    "\n",
    "## Setup\n",
    "1. Runtime â†’ Change runtime type â†’ GPU (T4)\n",
    "2. Upload dataset to Google Drive or use upload cell\n",
    "3. Run cells sequentially\n",
    "\n",
    "## Dataset Structure Expected\n",
    "```\n",
    "f1_scenes_dataset/\n",
    "â”œâ”€â”€ processed/\n",
    "â”‚   â”œâ”€â”€ train/\n",
    "â”‚   â”‚   â”œâ”€â”€ racing_action/\n",
    "â”‚   â”‚   â”œâ”€â”€ portrait_paddock/\n",
    "â”‚   â”‚   â”œâ”€â”€ podium_celebration/\n",
    "â”‚   â”‚   â”œâ”€â”€ garage_pitlane/\n",
    "â”‚   â”‚   â””â”€â”€ crowd_scene/\n",
    "â”‚   â”œâ”€â”€ val/\n",
    "â”‚   â””â”€â”€ test/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install"
   },
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q tensorflow pillow tensorflowjs matplotlib seaborn\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f\"\\nâœ… TensorFlow version: {tf.__version__}\")\n",
    "print(f\"âœ… GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mount_drive"
   },
   "source": "# Mount Google Drive\nfrom google.colab import drive\nimport os\nfrom pathlib import Path\n\ndrive.mount('/content/drive')\n\nprint(\"\\nğŸ” Searching for dataset on Google Drive...\\n\")\n\n# Possible dataset locations on Drive\nPOSSIBLE_PATHS = [\n    '/content/drive/MyDrive/f1_scenes_dataset',\n    '/content/drive/MyDrive/RaceTagger/f1_scenes_dataset',\n    '/content/drive/MyDrive/ml-training/f1_scenes_dataset',\n]\n\n# Find dataset\nDATASET_ROOT = None\nfor path in POSSIBLE_PATHS:\n    if os.path.exists(path):\n        DATASET_ROOT = path\n        print(f\"âœ… Dataset found: {path}\")\n        break\n\nif DATASET_ROOT is None:\n    print(\"âŒ Dataset not found in common locations!\")\n    print(\"\\nğŸ“‚ Available folders in MyDrive:\")\n    !ls -la /content/drive/MyDrive/\n    print(\"\\nâš ï¸  Please upload f1_scenes_dataset to MyDrive root\")\n    print(\"   Expected structure:\")\n    print(\"   MyDrive/\")\n    print(\"   â””â”€â”€ f1_scenes_dataset/\")\n    print(\"       â””â”€â”€ processed/\")\n    print(\"           â”œâ”€â”€ train/\")\n    print(\"           â”œâ”€â”€ val/\")\n    print(\"           â””â”€â”€ test/\")\n    raise FileNotFoundError(\"Dataset not found on Google Drive\")\n\n# Set processed dataset path\nDATASET_PATH = os.path.join(DATASET_ROOT, 'processed')\n\n# Verify structure\nrequired_dirs = ['train', 'val', 'test']\nfor subdir in required_dirs:\n    subdir_path = os.path.join(DATASET_PATH, subdir)\n    if not os.path.exists(subdir_path):\n        print(f\"âŒ Missing directory: {subdir}\")\n        raise FileNotFoundError(f\"Expected directory not found: {subdir_path}\")\n    \n    # Check categories\n    categories = os.listdir(subdir_path)\n    print(f\"âœ… {subdir:5s}: {len(categories)} categories - {categories}\")\n\nprint(f\"\\nâœ… Dataset ready: {DATASET_PATH}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "config"
   },
   "source": [
    "# Configuration\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Training config\n",
    "INPUT_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Categories\n",
    "CATEGORIES = [\n",
    "    'crowd_scene',\n",
    "    'garage_pitlane', \n",
    "    'podium_celebration',\n",
    "    'portrait_paddock',\n",
    "    'racing_action'\n",
    "]\n",
    "NUM_CLASSES = len(CATEGORIES)\n",
    "\n",
    "# Model-specific configs\n",
    "CONFIGS = {\n",
    "    'mobilenet': {\n",
    "        'phase1_epochs': 20,\n",
    "        'phase1_lr': 1e-3,\n",
    "        'phase2_epochs': 40,  # Increased from 30\n",
    "        'phase2_lr': 5e-5,    # More conservative\n",
    "        'unfreeze_layers': 30,  # More layers\n",
    "        'dense_units': 256,\n",
    "        'dropout': 0.3\n",
    "    },\n",
    "    'resnet18': {\n",
    "        'phase1_epochs': 15,\n",
    "        'phase1_lr': 1e-3,\n",
    "        'phase2_epochs': 30,\n",
    "        'phase2_lr': 1e-4,\n",
    "        'unfreeze_layers': 40,\n",
    "        'dense_units': 512,\n",
    "        'dropout': 0.4\n",
    "    },\n",
    "    'efficientnet': {\n",
    "        'phase1_epochs': 15,\n",
    "        'phase1_lr': 1e-3,\n",
    "        'phase2_epochs': 35,\n",
    "        'phase2_lr': 1e-4,\n",
    "        'unfreeze_layers': 30,\n",
    "        'dense_units': 384,\n",
    "        'dropout': 0.35\n",
    "    }\n",
    "}\n",
    "\n",
    "# Data augmentation\n",
    "ROTATION_RANGE = 15\n",
    "WIDTH_SHIFT = 0.1\n",
    "HEIGHT_SHIFT = 0.1\n",
    "ZOOM_RANGE = 0.15\n",
    "BRIGHTNESS_RANGE = (0.8, 1.2)\n",
    "\n",
    "print(\"âœ… Configuration loaded\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "data_loading"
   },
   "source": [
    "# Data loading utilities\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from typing import Tuple, Dict\n",
    "import numpy as np\n",
    "\n",
    "def compute_class_weights(train_dir: Path) -> Dict[int, float]:\n",
    "    \"\"\"Compute class weights for imbalanced datasets\"\"\"\n",
    "    class_counts = {}\n",
    "    \n",
    "    for i, category in enumerate(sorted(CATEGORIES)):\n",
    "        category_dir = train_dir / category\n",
    "        if category_dir.exists():\n",
    "            n_images = len(list(category_dir.glob('*.jpg')))\n",
    "            class_counts[i] = n_images\n",
    "    \n",
    "    total_images = sum(class_counts.values())\n",
    "    n_classes = len(class_counts)\n",
    "    \n",
    "    # Inverse frequency weighting\n",
    "    class_weights = {}\n",
    "    for i, count in class_counts.items():\n",
    "        weight = total_images / (n_classes * count)\n",
    "        class_weights[i] = weight\n",
    "    \n",
    "    return class_weights\n",
    "\n",
    "def create_data_generators() -> Tuple[ImageDataGenerator, ImageDataGenerator]:\n",
    "    \"\"\"Create training and validation data generators\"\"\"\n",
    "    # Training augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=ROTATION_RANGE,\n",
    "        width_shift_range=WIDTH_SHIFT,\n",
    "        height_shift_range=HEIGHT_SHIFT,\n",
    "        zoom_range=ZOOM_RANGE,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=BRIGHTNESS_RANGE,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Validation (only rescaling)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    return train_datagen, val_datagen\n",
    "\n",
    "def load_datasets(train_datagen, val_datagen, dataset_path):\n",
    "    \"\"\"Load train and validation datasets\"\"\"\n",
    "    train_path = Path(dataset_path) / 'train'\n",
    "    val_path = Path(dataset_path) / 'val'\n",
    "    \n",
    "    # Training set\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        str(train_path),\n",
    "        target_size=INPUT_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    # Validation set\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        str(val_path),\n",
    "        target_size=INPUT_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "# Load data\n",
    "train_datagen, val_datagen = create_data_generators()\n",
    "train_gen, val_gen = load_datasets(train_datagen, val_datagen, DATASET_PATH)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weights(Path(DATASET_PATH) / 'train')\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset Info:\")\n",
    "print(f\"  Train samples: {train_gen.samples}\")\n",
    "print(f\"  Val samples: {val_gen.samples}\")\n",
    "print(f\"  Classes: {CATEGORIES}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"\\nâš–ï¸  Class weights: {class_weights}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "model_builders"
   },
   "source": [
    "# Model building functions\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import (\n",
    "    MobileNetV3Small,\n",
    "    ResNet50,  # Colab might not have ResNet18, we'll use ResNet50 with fewer layers\n",
    "    EfficientNetB0\n",
    ")\n",
    "\n",
    "def build_mobilenet_model(num_classes: int, config: dict, freeze_base: bool = True):\n",
    "    \"\"\"\n",
    "    Build MobileNetV3-Small with FIXED training parameter.\n",
    "    BUG FIX: Removed training=False to allow batch norm updates during fine-tuning.\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ—ï¸  Building MobileNetV3-Small...\")\n",
    "    \n",
    "    base_model = MobileNetV3Small(\n",
    "        input_shape=(*INPUT_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        minimalistic=False\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = not freeze_base\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.Input(shape=(*INPUT_SIZE, 3))\n",
    "    \n",
    "    # BUG FIX: Remove training=False! This was blocking batch norm updates\n",
    "    x = base_model(inputs)  # Let Keras handle training mode automatically\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    x = layers.Dense(config['dense_units'], activation='relu', name='dense_classifier')(x)\n",
    "    x = layers.Dropout(config['dropout'], name='dropout')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name='mobilenet_scene_classifier')\n",
    "    \n",
    "    print(f\"  Total parameters: {model.count_params():,}\")\n",
    "    print(f\"  Base trainable: {not freeze_base}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_resnet_model(num_classes: int, config: dict, freeze_base: bool = True):\n",
    "    \"\"\"Build ResNet50 (simulating ResNet18 with fewer unfrozen layers)\"\"\"\n",
    "    print(\"\\nğŸ—ï¸  Building ResNet50 (ResNet18-like config)...\")\n",
    "    \n",
    "    base_model = ResNet50(\n",
    "        input_shape=(*INPUT_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = not freeze_base\n",
    "    \n",
    "    inputs = keras.Input(shape=(*INPUT_SIZE, 3))\n",
    "    x = base_model(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(config['dense_units'], activation='relu')(x)\n",
    "    x = layers.Dropout(config['dropout'])(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name='resnet_scene_classifier')\n",
    "    \n",
    "    print(f\"  Total parameters: {model.count_params():,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_efficientnet_model(num_classes: int, config: dict, freeze_base: bool = True):\n",
    "    \"\"\"Build EfficientNet-B0\"\"\"\n",
    "    print(\"\\nğŸ—ï¸  Building EfficientNet-B0...\")\n",
    "    \n",
    "    base_model = EfficientNetB0(\n",
    "        input_shape=(*INPUT_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = not freeze_base\n",
    "    \n",
    "    inputs = keras.Input(shape=(*INPUT_SIZE, 3))\n",
    "    x = base_model(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(config['dense_units'], activation='relu')(x)\n",
    "    x = layers.Dropout(config['dropout'])(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name='efficientnet_scene_classifier')\n",
    "    \n",
    "    print(f\"  Total parameters: {model.count_params():,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def unfreeze_top_layers(model, n_layers: int):\n",
    "    \"\"\"Unfreeze top N layers of base model for fine-tuning\"\"\"\n",
    "    base_model = model.layers[1]  # Base model is second layer\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-n_layers]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    trainable_count = sum([1 for layer in base_model.layers if layer.trainable])\n",
    "    print(f\"\\nğŸ”“ Unfrozen top {trainable_count}/{len(base_model.layers)} layers\")\n",
    "\n",
    "print(\"âœ… Model builders ready\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "training_utils"
   },
   "source": [
    "# Training utilities\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    "    Callback\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "def create_callbacks(model_name: str, phase: str):\n",
    "    \"\"\"Create training callbacks\"\"\"\n",
    "    callbacks = []\n",
    "    \n",
    "    # Model checkpoint\n",
    "    checkpoint_dir = Path(f'/content/checkpoints/{model_name}')\n",
    "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    checkpoint_cb = ModelCheckpoint(\n",
    "        str(checkpoint_dir / f'{phase}_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(checkpoint_cb)\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stop_cb = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(early_stop_cb)\n",
    "    \n",
    "    # Reduce learning rate\n",
    "    reduce_lr_cb = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(reduce_lr_cb)\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def train_two_phase(model, config: dict, model_name: str):\n",
    "    \"\"\"Two-phase transfer learning: freeze base, then fine-tune\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # PHASE 1: Train classification head\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸ”’ PHASE 1: Train Classification Head - {model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config['phase1_lr']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    phase1_callbacks = create_callbacks(model_name, 'phase1')\n",
    "    \n",
    "    history_phase1 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=config['phase1_epochs'],\n",
    "        callbacks=phase1_callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    results['phase1'] = history_phase1.history\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # PHASE 2: Fine-tune top layers\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸ”“ PHASE 2: Fine-tune Top Layers - {model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    unfreeze_top_layers(model, config['unfreeze_layers'])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config['phase2_lr']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    phase2_callbacks = create_callbacks(model_name, 'phase2')\n",
    "    \n",
    "    history_phase2 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=config['phase2_epochs'],\n",
    "        callbacks=phase2_callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    results['phase2'] = history_phase2.history\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ… Training utilities ready\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_mobilenet_header"
   },
   "source": [
    "## ğŸ“± Train MobileNetV3-Small (Fixed)\n",
    "\n",
    "Lightweight model with BUG FIX for `training=False` issue.\n",
    "\n",
    "**Target:**\n",
    "- Accuracy: 75-80%\n",
    "- Size: 2-3MB after quantization\n",
    "- Inference: <50ms\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "train_mobilenet"
   },
   "source": [
    "# Train MobileNetV3-Small\n",
    "mobilenet_model = build_mobilenet_model(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    config=CONFIGS['mobilenet'],\n",
    "    freeze_base=True\n",
    ")\n",
    "\n",
    "mobilenet_results = train_two_phase(\n",
    "    mobilenet_model,\n",
    "    CONFIGS['mobilenet'],\n",
    "    'mobilenet'\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "mobilenet_model.save('/content/mobilenet_scene_classifier_final.keras')\n",
    "\n",
    "# Print results\n",
    "final_val_acc = mobilenet_results['phase2']['val_accuracy'][-1]\n",
    "print(f\"\\nâœ… MobileNetV3 Final Validation Accuracy: {final_val_acc:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_resnet_header"
   },
   "source": [
    "## ğŸ—ï¸ Train ResNet50 (ResNet18-like config)\n",
    "\n",
    "More powerful model to replicate Roboflow results (89% accuracy).\n",
    "\n",
    "**Target:**\n",
    "- Accuracy: 85-92%\n",
    "- Size: 10-15MB after quantization\n",
    "- Inference: 80-120ms\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "train_resnet"
   },
   "source": [
    "# Train ResNet\n",
    "resnet_model = build_resnet_model(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    config=CONFIGS['resnet18'],\n",
    "    freeze_base=True\n",
    ")\n",
    "\n",
    "resnet_results = train_two_phase(\n",
    "    resnet_model,\n",
    "    CONFIGS['resnet18'],\n",
    "    'resnet'\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "resnet_model.save('/content/resnet_scene_classifier_final.keras')\n",
    "\n",
    "# Print results\n",
    "final_val_acc = resnet_results['phase2']['val_accuracy'][-1]\n",
    "print(f\"\\nâœ… ResNet Final Validation Accuracy: {final_val_acc:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_efficientnet_header"
   },
   "source": [
    "## âš¡ Train EfficientNet-B0\n",
    "\n",
    "Balanced model - compromise between size and accuracy.\n",
    "\n",
    "**Target:**\n",
    "- Accuracy: 80-88%\n",
    "- Size: 4-6MB after quantization\n",
    "- Inference: 50-80ms\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "train_efficientnet"
   },
   "source": [
    "# Train EfficientNet\n",
    "efficientnet_model = build_efficientnet_model(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    config=CONFIGS['efficientnet'],\n",
    "    freeze_base=True\n",
    ")\n",
    "\n",
    "efficientnet_results = train_two_phase(\n",
    "    efficientnet_model,\n",
    "    CONFIGS['efficientnet'],\n",
    "    'efficientnet'\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "efficientnet_model.save('/content/efficientnet_scene_classifier_final.keras')\n",
    "\n",
    "# Print results\n",
    "final_val_acc = efficientnet_results['phase2']['val_accuracy'][-1]\n",
    "print(f\"\\nâœ… EfficientNet Final Validation Accuracy: {final_val_acc:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison_header"
   },
   "source": [
    "## ğŸ“Š Model Comparison\n",
    "\n",
    "Compare all trained models and select the best one.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "comparison"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Collect results\n",
    "comparison = {\n",
    "    'Model': ['MobileNetV3-Small', 'ResNet50', 'EfficientNet-B0'],\n",
    "    'Val Accuracy': [\n",
    "        mobilenet_results['phase2']['val_accuracy'][-1],\n",
    "        resnet_results['phase2']['val_accuracy'][-1],\n",
    "        efficientnet_results['phase2']['val_accuracy'][-1]\n",
    "    ],\n",
    "    'Val Loss': [\n",
    "        mobilenet_results['phase2']['val_loss'][-1],\n",
    "        resnet_results['phase2']['val_loss'][-1],\n",
    "        efficientnet_results['phase2']['val_loss'][-1]\n",
    "    ],\n",
    "    'Parameters (M)': [\n",
    "        mobilenet_model.count_params() / 1e6,\n",
    "        resnet_model.count_params() / 1e6,\n",
    "        efficientnet_model.count_params() / 1e6\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison)\n",
    "df = df.sort_values('Val Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = df.iloc[0]['Model']\n",
    "best_accuracy = df.iloc[0]['Val Accuracy']\n",
    "\n",
    "print(f\"\\nğŸ† BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.bar(df['Model'], df['Val Accuracy'])\n",
    "ax1.set_ylabel('Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy Comparison')\n",
    "ax1.axhline(y=0.88, color='r', linestyle='--', label='Target (88%)')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "ax2.bar(df['Model'], df['Parameters (M)'])\n",
    "ax2.set_ylabel('Parameters (Millions)')\n",
    "ax2.set_title('Model Size Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/model_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Comparison complete!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_header"
   },
   "source": [
    "## ğŸ“¦ Export to TensorFlow.js\n",
    "\n",
    "Convert best model to TensorFlow.js format for browser/Electron deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "export_tfjs"
   },
   "source": [
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Select best model for export\n",
    "# Manually set or use comparison results\n",
    "best_model_file = '/content/resnet_scene_classifier_final.keras'  # Change based on results\n",
    "best_model_name = 'resnet'  # Change based on results\n",
    "\n",
    "# Load best model\n",
    "best_model = keras.models.load_model(best_model_file)\n",
    "\n",
    "# Export to TensorFlow.js\n",
    "tfjs_output_dir = f'/content/tfjs_models/{best_model_name}'\n",
    "tfjs.converters.save_keras_model(best_model, tfjs_output_dir)\n",
    "\n",
    "print(f\"\\nâœ… Model exported to: {tfjs_output_dir}\")\n",
    "\n",
    "# Export quantized version (int8)\n",
    "tfjs_quantized_dir = f'/content/tfjs_models/{best_model_name}_quantized'\n",
    "tfjs.converters.save_keras_model(\n",
    "    best_model,\n",
    "    tfjs_quantized_dir,\n",
    "    quantization_dtype_map={'uint8': '*'}  # Quantize all layers\n",
    ")\n",
    "\n",
    "print(f\"âœ… Quantized model exported to: {tfjs_quantized_dir}\")\n",
    "\n",
    "# Save class labels\n",
    "class_labels = {\n",
    "    'categories': CATEGORIES,\n",
    "    'category_to_index': {cat: i for i, cat in enumerate(CATEGORIES)},\n",
    "    'index_to_category': {i: cat for i, cat in enumerate(CATEGORIES)},\n",
    "    'input_size': INPUT_SIZE,\n",
    "    'num_classes': NUM_CLASSES\n",
    "}\n",
    "\n",
    "with open(f'{tfjs_output_dir}/class_labels.json', 'w') as f:\n",
    "    json.dump(class_labels, f, indent=2)\n",
    "\n",
    "with open(f'{tfjs_quantized_dir}/class_labels.json', 'w') as f:\n",
    "    json.dump(class_labels, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… Export complete!\")\n",
    "print(\"\\nğŸ“¦ Download files:\")\n",
    "print(f\"   - {tfjs_output_dir}/\")\n",
    "print(f\"   - {tfjs_quantized_dir}/\")\n",
    "\n",
    "# Create zip for easy download\n",
    "!zip -r /content/scene_classifier_tfjs.zip /content/tfjs_models/\n",
    "print(\"\\nâœ… Created zip: /content/scene_classifier_tfjs.zip\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_header"
   },
   "source": [
    "## ğŸ§ª Test Model on Sample Images\n",
    "\n",
    "Validate exported model on test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "test_model"
   },
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load test images\n",
    "test_dir = Path(DATASET_PATH) / 'test'\n",
    "\n",
    "# Test on random images from each category\n",
    "print(\"\\nğŸ§ª Testing model on sample images...\\n\")\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    category_dir = test_dir / category\n",
    "    if not category_dir.exists():\n",
    "        continue\n",
    "    \n",
    "    test_images = list(category_dir.glob('*.jpg'))[:3]  # Test 3 images per category\n",
    "    \n",
    "    for img_path in test_images:\n",
    "        # Load and preprocess image\n",
    "        img = image.load_img(img_path, target_size=INPUT_SIZE)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0\n",
    "        \n",
    "        # Predict\n",
    "        predictions = best_model.predict(img_array, verbose=0)\n",
    "        predicted_class = CATEGORIES[np.argmax(predictions[0])]\n",
    "        confidence = np.max(predictions[0])\n",
    "        \n",
    "        # Check if correct\n",
    "        correct = \"âœ…\" if predicted_class == category else \"âŒ\"\n",
    "        \n",
    "        print(f\"{correct} True: {category:20s} | Predicted: {predicted_class:20s} | Confidence: {confidence:.2%}\")\n",
    "\n",
    "print(\"\\nâœ… Testing complete!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_header"
   },
   "source": [
    "## ğŸ“¥ Download Models\n",
    "\n",
    "Download trained models and TensorFlow.js exports to your local machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "download"
   },
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download options\n",
    "print(\"\\nğŸ“¥ Available downloads:\\n\")\n",
    "print(\"1. TensorFlow.js models (all formats): scene_classifier_tfjs.zip\")\n",
    "print(\"2. Best Keras model: best_scene_classifier.keras\")\n",
    "print(\"3. Training history: training_results.json\")\n",
    "\n",
    "# Save training results\n",
    "training_summary = {\n",
    "    'mobilenet': {\n",
    "        'final_val_acc': float(mobilenet_results['phase2']['val_accuracy'][-1]),\n",
    "        'final_val_loss': float(mobilenet_results['phase2']['val_loss'][-1]),\n",
    "        'parameters': int(mobilenet_model.count_params())\n",
    "    },\n",
    "    'resnet': {\n",
    "        'final_val_acc': float(resnet_results['phase2']['val_accuracy'][-1]),\n",
    "        'final_val_loss': float(resnet_results['phase2']['val_loss'][-1]),\n",
    "        'parameters': int(resnet_model.count_params())\n",
    "    },\n",
    "    'efficientnet': {\n",
    "        'final_val_acc': float(efficientnet_results['phase2']['val_accuracy'][-1]),\n",
    "        'final_val_loss': float(efficientnet_results['phase2']['val_loss'][-1]),\n",
    "        'parameters': int(efficientnet_model.count_params())\n",
    "    },\n",
    "    'best_model': best_model_name,\n",
    "    'dataset_info': {\n",
    "        'train_samples': train_gen.samples,\n",
    "        'val_samples': val_gen.samples,\n",
    "        'categories': CATEGORIES\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('/content/training_results.json', 'w') as f:\n",
    "    json.dump(training_summary, f, indent=2)\n",
    "\n",
    "# Download files\n",
    "print(\"\\nğŸš€ Starting downloads...\\n\")\n",
    "\n",
    "# TensorFlow.js zip\n",
    "files.download('/content/scene_classifier_tfjs.zip')\n",
    "\n",
    "# Best model\n",
    "files.download(best_model_file)\n",
    "\n",
    "# Training results\n",
    "files.download('/content/training_results.json')\n",
    "\n",
    "# Model comparison plot\n",
    "files.download('/content/model_comparison.png')\n",
    "\n",
    "print(\"\\nâœ… All downloads complete!\")\n",
    "print(\"\\nğŸ“‹ Next steps:\")\n",
    "print(\"1. Extract scene_classifier_tfjs.zip\")\n",
    "print(\"2. Copy TensorFlow.js model to RaceTagger project\")\n",
    "print(\"3. Test inference performance in Electron app\")\n",
    "print(\"4. Compare quantized vs non-quantized model sizes and speeds\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}