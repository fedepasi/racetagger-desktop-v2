# RF-DETR to ONNX - Google Colab Notebook

## ðŸ““ Notebook Disponibile

**[RF_DETR_to_ONNX_Conversion_Colab.ipynb](./RF_DETR_to_ONNX_Conversion_Colab.ipynb)**

Notebook Jupyter interattivo per convertire modelli RF-DETR (`.pt`) in formato ONNX usando Google Colab.

## ðŸš€ Come Usare

### Opzione 1: Google Colab (Raccomandato)

1. **Apri il notebook**
   - Vai su [Google Colab](https://colab.research.google.com/)
   - File â†’ Upload â†’ Seleziona `RF_DETR_to_ONNX_Conversion_Colab.ipynb`

2. **Esegui le celle in ordine**
   - âœ… **Cella 1**: Installa dipendenze (2-3 minuti)
   - âœ… **Cella 2**: Upload del file `.pt` (o monta Google Drive)
   - âœ… **Cella 3**: Analisi checkpoint (auto-detect model size)
   - âœ… **Cella 4**: Conversione ONNX (1-2 minuti)
   - âœ… **Cella 5**: Test inferenza (opzionale)
   - âœ… **Cella 6**: Download file `.onnx`

3. **Scarica il risultato**
   - Il file `.onnx` viene scaricato automaticamente
   - Copia il checksum SHA256 per upload al Management Portal

### Opzione 2: Jupyter Locale

```bash
cd ml-training/notebooks

# Attiva virtual environment
source ../venv-ml/bin/activate

# Installa Jupyter (se non giÃ  fatto)
pip install jupyter

# Avvia notebook
jupyter notebook RF_DETR_to_ONNX_Conversion_Colab.ipynb
```

## ðŸ“‹ Cosa Fa il Notebook

### Automatico
- âœ… Installazione dipendenze (rfdetr, onnx, torch)
- âœ… Rilevamento automatico model size
- âœ… Conversione con legacy exporter (PyTorch 2.9+ compatible)
- âœ… Verifica e semplificazione ONNX
- âœ… Calcolo checksum SHA256
- âœ… Test inferenza opzionale

### Input Richiesto
- File `.pt` o `.pth` del modello trainato
- (Opzionale) Resolution custom se auto-detect fallisce

### Output
- File `.onnx` convertito
- Checksum SHA256
- Report con info modello (size, resolution, etc.)

## âš¡ Vantaggi Google Colab

- âœ… **No setup locale**: Nessuna installazione su computer
- âœ… **GPU gratuita**: T4 GPU per accelerazione (se disponibile)
- âœ… **RAM abbondante**: 12-13 GB RAM gratuiti
- âœ… **Cloud storage**: Salva in Google Drive direttamente
- âœ… **Multi-platform**: Funziona da Windows/Mac/Linux

## ðŸŽ¯ Quando Usare il Notebook

**Usa il notebook Colab quando:**
- Non vuoi installare dipendenze localmente
- Hai un computer con RAM limitata
- Vuoi conversione guidata step-by-step
- Preferisci interfaccia visuale interattiva
- Hai file sul Google Drive

**Usa gli script Python quando:**
- Vuoi automazione completa (batch processing)
- Hai giÃ  ambiente locale configurato
- Preferisci CLI/terminale
- Vuoi integrare in pipeline CI/CD

## ðŸ“Š Struttura Notebook

```
1. Setup & Installazione
   â”œâ”€ pip install dipendenze
   â””â”€ Import librerie

2. Upload Modello
   â”œâ”€ Option A: Upload manuale
   â””â”€ Option B: Google Drive mount

3. Ispezione Checkpoint
   â”œâ”€ Analisi args.resolution
   â”œâ”€ Analisi args.hidden_dim
   â””â”€ Auto-detect model type

4. Conversione ONNX
   â”œâ”€ Caricamento modello
   â”œâ”€ Preparazione export
   â”œâ”€ torch.onnx.export (dynamo=False)
   â”œâ”€ onnx.checker.check_model()
   â””â”€ onnxsim.simplify()

5. Test (Opzionale)
   â”œâ”€ Caricamento ONNX Runtime
   â”œâ”€ Test inference
   â””â”€ Verifica output shapes

6. Download
   â””â”€ files.download() â†’ file .onnx
```

## ðŸ”§ Customizzazione

Se l'auto-detect fallisce, puoi modificare manualmente:

```python
# Nella cella "Conversione ONNX", modifica:
model_type = 'RFDETRSmall'  # Uncomment e modifica
resolution = 512             # Uncomment e modifica
```

Model types supportati:
- `RFDETRNano` (res: 384)
- `RFDETRSmall` (res: 512)
- `RFDETRMedium` (res: 576)
- `RFDETRBase` (res: 560, hidden: 256)
- `RFDETRLarge` (res: 560, hidden: 384)
- `RFDETRSegPreview` (segmentation)

## âš ï¸ Note Importanti

### PyTorch 2.9+ Compatibility
Il notebook usa automaticamente `dynamo=False` per compatibilitÃ  con PyTorch 2.9+.

### MPS Fallback (Mac M-series)
Se usi localmente su Mac M-series, il notebook forza CPU con `.cpu()` per evitare problemi MPS.

### Limiti Google Colab

**Versione Gratuita:**
- Timeout: 12 ore max sessione
- RAM: ~12 GB
- Disco: ~100 GB
- GPU: T4 (quando disponibile, non garantita)

**Colab Pro (â‚¬10/mese):**
- Timeout: 24 ore
- RAM: ~25 GB
- GPU priority: P100/V100

## ðŸ“š Documentazione Completa

Per dettagli completi su metodi alternativi, troubleshooting e post-processing:

âž¡ï¸ **[../CONVERSION_GUIDE.md](../CONVERSION_GUIDE.md)**

---

## ðŸ†˜ Troubleshooting

### Cella "Installazione" fallisce

**Problema**: Timeout o errori pip

**Soluzione**:
```python
# Nella cella installazione, aggiungi:
!pip install --no-cache-dir rfdetr==1.3.0 onnx==1.19.0 ...
```

### Upload fallisce (file > 100 MB)

**Problema**: Timeout durante upload

**Soluzione**: Usa Google Drive mount invece di upload manuale
```python
from google.colab import drive
drive.mount('/content/drive')
checkpoint_path = '/content/drive/MyDrive/path/to/model.pt'
```

### Auto-detect fallisce

**Problema**: `model_type = 'Unknown'`

**Soluzione**: Modifica manualmente nella cella conversione (vedi sezione Customizzazione)

### Conversione lenta

**Problema**: >5 minuti per convertire

**Possibili cause**:
- Modello molto grande (>500 MB)
- Colab senza GPU assegnata
- Semplificazione ONNX lenta

**Soluzione**: Disabilita semplificazione temporaneamente
```python
# Nella cella conversione, commenta:
# model_simplified, check = simplify(onnx_model)
```

---

**Creato per**: RaceTagger Desktop
**Ultimo aggiornamento**: 2026-01-18
**Versioni testate**: PyTorch 2.8.0, ONNX 1.19.0, rfdetr 1.3.0
